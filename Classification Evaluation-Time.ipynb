{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ae7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5322c93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_953600/81534717.py:3: DtypeWarning: Columns (2,6,7,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "file_path='total_new.csv'\n",
    "df=pd.read_csv(file_path)\n",
    "df['Metadata_experiment_type'].value_counts()\n",
    "df[\"Metadata_gene\"]=df[\"Metadata_gene\"].fillna('empty')\n",
    "df_fill_empty=df\n",
    "df_negcon=df_fill_empty[df_fill_empty['Metadata_control_type']=='negcon']\n",
    "df_rm_negcon=df_fill_empty[df_fill_empty['Metadata_control_type']!='negcon']\n",
    "df_rm_empty_gene=df_fill_empty[df_fill_empty['Metadata_gene']!='empty']\n",
    "df_rm_orf=df_rm_empty_gene[df_rm_empty_gene[\"Metadata_experiment_type\"]!='ORF']\n",
    "\n",
    "# sampling\n",
    "df_proceed=df_rm_orf[~df_rm_orf['Metadata_pert_type'].isin(['control'])]\n",
    "# Time\n",
    "df_test=df_proceed[df_proceed['Metadata_Plate'].isin(\n",
    "['BR00116996',\n",
    " 'BR00116997',\n",
    " 'BR00116998',\n",
    " 'BR00116999',\n",
    " 'BR00118045',\n",
    " 'BR00118046',\n",
    " 'BR00118047',\n",
    " 'BR00118048'])]\n",
    "df_train=df_proceed[df_proceed['Metadata_Plate'].isin(\n",
    "['BR00116995',\n",
    " 'BR00117010',\n",
    " 'BR00117012',\n",
    " 'BR00117013',\n",
    " 'BR00117024',\n",
    " 'BR00117025',\n",
    " 'BR00117026'])]\n",
    "# Train_test pre-process\n",
    "y_train=df_train['Metadata_gene']\n",
    "trainX=df_train.drop('Metadata_gene', axis = 1)\n",
    "testX=df_test.drop('Metadata_gene', axis = 1)\n",
    "y_test = df_test['Metadata_gene']\n",
    "trainX=trainX.iloc[:,trainX.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\"):]\n",
    "testX=testX.iloc[:,testX.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\"):]\n",
    "trainX=np.array(trainX)\n",
    "testX=np.array(testX)\n",
    "trainY=np.array(y_train)\n",
    "testY=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddc9148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "\n",
    "# Scale the training and test sets using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "trainX_scaled = scaler.fit_transform(trainX)\n",
    "testX_scaled = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "978b6c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.60348608\n",
      "Iteration 2, loss = 3.48315637\n",
      "Iteration 3, loss = 2.73037948\n",
      "Iteration 4, loss = 2.17175646\n",
      "Iteration 5, loss = 1.75234468\n",
      "Iteration 6, loss = 1.37306283\n",
      "Iteration 7, loss = 1.06496667\n",
      "Iteration 8, loss = 0.85365395\n",
      "Iteration 9, loss = 0.62524282\n",
      "Iteration 10, loss = 0.46726050\n",
      "Iteration 11, loss = 0.37455810\n",
      "Iteration 12, loss = 0.27183853\n",
      "Iteration 13, loss = 0.20804810\n",
      "Iteration 14, loss = 0.15290567\n",
      "Iteration 15, loss = 0.11767660\n",
      "Iteration 16, loss = 0.08597500\n",
      "Iteration 17, loss = 0.06157549\n",
      "Iteration 18, loss = 0.04229272\n",
      "Iteration 19, loss = 0.03615371\n",
      "Iteration 20, loss = 0.02502646\n",
      "Iteration 21, loss = 0.01748486\n",
      "Iteration 22, loss = 0.01586463\n",
      "Iteration 23, loss = 0.01228448\n",
      "Iteration 24, loss = 0.01203596\n",
      "Iteration 25, loss = 0.01009160\n",
      "Iteration 26, loss = 0.00935808\n",
      "Iteration 27, loss = 0.00843256\n",
      "Iteration 28, loss = 0.00787236\n",
      "Iteration 29, loss = 0.00733970\n",
      "Iteration 30, loss = 0.00687145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchen.yang@insilico.ai/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(1280, 630, 300), max_iter=30, tol=1e-08,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(1280, 630, 300), max_iter=30, tol=1e-08,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(1280, 630, 300), max_iter=30, tol=1e-08,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "\n",
    "# Scale the training and test sets using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "trainX_scaled = scaler.fit_transform(trainX)\n",
    "testX_scaled = scaler.transform(testX)\n",
    "\n",
    "# Train the MLPClassifier model\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(1280, 630, 300),\n",
    "                        max_iter=30, activation='relu', verbose=True, tol=1e-8,\n",
    "                        solver='adam')\n",
    "mlp_clf.fit(trainX_scaled, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f52d60",
   "metadata": {},
   "source": [
    "These below are MLP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44ec86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug in mode = 'top_1' if you want to apply normal MLP classification\n",
    "# plug in mode = 'top_10' if you want to get the top 10 highest \n",
    "def Compute_MLP_Result(trainX,testX,testY,trainY,mode):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.metrics import classification_report, recall_score\n",
    "    if mode == 'top_1':\n",
    "    # MLP TOP ONE (Not TOP TEN)\n",
    "        sc=StandardScaler()\n",
    "        scaler = sc.fit(trainX)\n",
    "        trainX_scaled = scaler.transform(trainX)\n",
    "        testX_scaled = scaler.transform(testX)\n",
    "        y_pred = mlp_clf.predict(testX_scaled)\n",
    "    #print('Seen')\n",
    "    #print(classification_report(testY, y_pred))\n",
    "        report=classification_report(testY, y_pred,output_dict=True)\n",
    "        result=pd.DataFrame(report).transpose()[['recall']]\n",
    "        result.rename(columns={'recall': 'Recall'},inplace=True)\n",
    "        result.drop(['micro avg','macro avg','weighted avg'],axis=0,errors='ignore',inplace = True)\n",
    "        result.index.name='Label'\n",
    "        result=result[result.index.isin(pd.Series(testY).unique())]\n",
    "        return result\n",
    "    if mode =='top_10':\n",
    "        # MLP Top Ten\n",
    "\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(testX)\n",
    "        le = LabelEncoder()\n",
    "        trainY_encoded = le.fit_transform(trainY)\n",
    "        testY_encoded = le.transform(testY)\n",
    "        y_pred_probs = mlp_clf.predict_proba(sc.transform(testX))\n",
    "\n",
    "# Initialize a dictionary to keep track of the number of correct predictions for each label\n",
    "        label_counts = {label: {'total': 0, 'correct': 0} for label in set(testY)}\n",
    "\n",
    "# Loop over each sample in the test set\n",
    "        for i in range(len(testY)):\n",
    "            true_label = testY[i]\n",
    "            true_label_encoded = testY_encoded[i]\n",
    "            top_ten_labels_encoded = np.argsort(y_pred_probs[i])[::-1][:10]\n",
    "            top_ten_labels = le.inverse_transform(top_ten_labels_encoded)\n",
    "            if true_label in top_ten_labels:\n",
    "                label_counts[true_label]['correct'] += 1\n",
    "            label_counts[true_label]['total'] += 1\n",
    "\n",
    "# Calculate the accuracy for each label and print the results\n",
    "        for label, counts in label_counts.items():\n",
    "            if counts['total'] > 0:\n",
    "                accuracy = counts['correct'] / counts['total']\n",
    "                print(f\"Label {label}: {accuracy:.2f} ({counts['correct']}/{counts['total']})\")\n",
    "            else:\n",
    "                print(f\"Label {label}: No samples in test set\")\n",
    "\n",
    "# Calculate the accuracy for each label and store the results in a dictionary\n",
    "        accuracy_dict = {}\n",
    "        for label, counts in label_counts.items():\n",
    "            if counts['total'] > 0:\n",
    "                accuracy = counts['correct'] / counts['total']\n",
    "                accuracy_dict[label] = accuracy\n",
    "\n",
    "# Create a DataFrame with the accuracy for each label\n",
    "        accuracy_df = pd.DataFrame.from_dict(accuracy_dict, orient='index', columns=['Accuracy'])\n",
    "        accuracy_df.index.name = 'Label'\n",
    "        accuracy_df = accuracy_df.sort_values(by='Accuracy', ascending=False)\n",
    "        return accuracy_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e96e0dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchen.yang@insilico.ai/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yuchen.yang@insilico.ai/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yuchen.yang@insilico.ai/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label ANXA1: 0.25 (4/16)\n",
      "Label BAX: 0.44 (7/16)\n",
      "Label PNLIP: 0.38 (6/16)\n",
      "Label ADORA2A: 0.31 (5/16)\n",
      "Label PPAT: 0.19 (3/16)\n",
      "Label KCNN1: 0.19 (3/16)\n",
      "Label TNF: 0.06 (1/16)\n",
      "Label HSP90AB1: 0.12 (2/16)\n",
      "Label GPR119: 0.12 (2/16)\n",
      "Label DDR2: 0.00 (0/16)\n",
      "Label ATM: 0.12 (2/16)\n",
      "Label GPR55: 0.19 (3/16)\n",
      "Label HSD11B1: 0.38 (6/16)\n",
      "Label SLCO2B1: 0.06 (1/16)\n",
      "Label GUCY1B1: 0.19 (3/16)\n",
      "Label SLC29A1: 0.12 (2/16)\n",
      "Label FFAR4: 0.00 (0/16)\n",
      "Label HTR3A: 0.00 (0/16)\n",
      "Label ADA: 0.00 (0/16)\n",
      "Label CDK4: 0.12 (2/16)\n",
      "Label LYN: 0.12 (2/16)\n",
      "Label S1PR1: 0.00 (0/16)\n",
      "Label PPARD: 0.00 (0/16)\n",
      "Label GHSR: 0.00 (0/16)\n",
      "Label CCR1: 0.00 (0/16)\n",
      "Label PTPN2: 0.00 (0/16)\n",
      "Label SIRT2: 0.00 (0/16)\n",
      "Label PLD1: 0.25 (4/16)\n",
      "Label FGF1: 0.00 (0/16)\n",
      "Label DCK: 0.00 (0/16)\n",
      "Label AKR1B1: 0.00 (0/16)\n",
      "Label CCND1: 0.06 (1/16)\n",
      "Label PTK2B: 0.06 (1/16)\n",
      "Label TNNC1: 0.31 (5/16)\n",
      "Label HRH4: 0.06 (1/16)\n",
      "Label CTSG: 0.19 (3/16)\n",
      "Label COMT: 0.50 (8/16)\n",
      "Label IL1B: 0.19 (3/16)\n",
      "Label PDE3A: 0.12 (2/16)\n",
      "Label FOXM1: 0.00 (0/16)\n",
      "Label ABL1: 0.06 (1/16)\n",
      "Label TUBB4B: 0.06 (1/16)\n",
      "Label HDAC6: 0.00 (0/16)\n",
      "Label PARP3: 0.00 (0/16)\n",
      "Label FFAR2: 0.38 (6/16)\n",
      "Label TGM2: 0.19 (3/16)\n",
      "Label TUBB3: 0.19 (3/16)\n",
      "Label P2RY12: 0.06 (1/16)\n",
      "Label ALK: 0.00 (0/16)\n",
      "Label OPRM1: 0.12 (2/16)\n",
      "Label F10: 0.06 (1/16)\n",
      "Label CYP3A4: 0.00 (0/16)\n",
      "Label ASIC1: 0.00 (0/16)\n",
      "Label SLC7A11: 0.06 (1/16)\n",
      "Label ELANE: 0.19 (3/16)\n",
      "Label KCNN4: 0.00 (0/16)\n",
      "Label KCNQ2: 0.25 (4/16)\n",
      "Label UGT1A9: 0.00 (0/16)\n",
      "Label ITGB2: 0.12 (2/16)\n",
      "Label PTGIS: 0.12 (2/16)\n",
      "Label HPGDS: 0.00 (0/16)\n",
      "Label CA5A: 0.00 (0/16)\n",
      "Label PDE4D: 0.19 (3/16)\n",
      "Label PRKCE: 0.12 (2/16)\n",
      "Label CATSPER4: 0.06 (1/16)\n",
      "Label KCNJ1: 0.00 (0/16)\n",
      "Label KCTD16: 0.00 (0/16)\n",
      "Label PORCN: 0.19 (3/16)\n",
      "Label VEGFA: 0.00 (0/16)\n",
      "Label EDNRB: 0.00 (0/16)\n",
      "Label HIF1A: 0.06 (1/16)\n",
      "Label CA14: 0.12 (2/16)\n",
      "Label TBXAS1: 0.19 (3/16)\n",
      "Label S100B: 0.00 (0/16)\n",
      "Label PLA2G1B: 0.00 (0/16)\n",
      "Label GRIN2A: 0.00 (0/16)\n",
      "Label OPRL1: 0.12 (2/16)\n",
      "Label CSF1R: 0.00 (0/16)\n",
      "Label ICAM1: 0.00 (0/16)\n",
      "Label GLRA3: 0.06 (1/16)\n",
      "Label CYP1A2: 0.44 (7/16)\n",
      "Label CASP3: 0.06 (1/16)\n",
      "Label CYP2A6: 0.00 (0/16)\n",
      "Label TGFBR1: 0.12 (2/16)\n",
      "Label CACNB4: 0.38 (6/16)\n",
      "Label ALDH2: 0.00 (0/16)\n",
      "Label HCK: 0.12 (2/16)\n",
      "Label AVPR1A: 0.00 (0/16)\n",
      "Label HTR2C: 0.38 (6/16)\n",
      "Label HBB: 0.31 (5/16)\n",
      "Label S1PR4: 0.00 (0/16)\n",
      "Label CSK: 0.44 (7/16)\n",
      "Label DHH: 0.00 (0/16)\n",
      "Label CDK9: 0.06 (1/16)\n",
      "Label RPL3: 0.19 (3/16)\n",
      "Label NTRK1: 0.06 (1/16)\n",
      "Label GAA: 0.06 (1/16)\n",
      "Label CDC25A: 0.06 (1/16)\n",
      "Label ADRA2B: 0.12 (2/16)\n",
      "Label PTGIR: 0.12 (2/16)\n",
      "Label S1PR2: 0.06 (1/16)\n",
      "Label PDPK1: 0.12 (2/16)\n",
      "Label FPR1: 0.06 (1/16)\n",
      "Label ATP5F1D: 0.06 (1/16)\n",
      "Label KCNK1: 0.00 (0/16)\n",
      "Label AKR1C1: 0.00 (0/16)\n",
      "Label CHRM2: 0.06 (1/16)\n",
      "Label CACNG1: 0.19 (3/16)\n",
      "Label MMP2: 0.00 (0/16)\n",
      "Label PDE7A: 0.06 (1/16)\n",
      "Label MME: 0.06 (1/16)\n",
      "Label SSTR2: 0.00 (0/16)\n",
      "Label CACNA2D3: 0.44 (7/16)\n",
      "Label MAPK8: 0.31 (5/16)\n",
      "Label RNASE1: 0.00 (0/16)\n",
      "Label SCNN1G: 0.31 (5/16)\n",
      "Label BTK: 0.56 (9/16)\n",
      "Label KDR: 0.00 (0/16)\n",
      "Label LCK: 0.06 (1/16)\n",
      "Label PRKCB: 0.12 (2/16)\n",
      "Label CHRM3: 0.00 (0/16)\n",
      "Label RPL23A: 0.44 (7/16)\n",
      "Label LPAR1: 0.25 (4/16)\n",
      "Label AGER: 0.19 (3/16)\n",
      "Label KCNH7: 0.12 (2/16)\n",
      "Label RGS4: 0.19 (3/16)\n",
      "Label GJB4: 0.00 (0/16)\n",
      "Label ADH1C: 0.25 (4/16)\n",
      "Label P3H1: 0.12 (2/16)\n",
      "Label KCNMA1: 0.06 (1/16)\n"
     ]
    }
   ],
   "source": [
    "# top1 / Top 10 Result \n",
    "top1_seen_result=Compute_MLP_Result(trainX,testX,testY,trainY,'top_1')\n",
    "top10_seen_result=Compute_MLP_Result(trainX,testX,testY,trainY,'top_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a58623fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP top1 0.010096153846153847\n",
      "MLP top10 0.11682692307692308\n"
     ]
    }
   ],
   "source": [
    "print('MLP top1',top1_seen_result['Recall'].mean())\n",
    "print('MLP top10',top10_seen_result['Accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eae19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ad7bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def kNCM(trainX, trainY, testX, testY, k, mode):\n",
    "    # Convert the label strings to integers\n",
    "    label_to_int = {label: i for i, label in enumerate(set(trainY))}\n",
    "    trainY_int = np.array([label_to_int[label] for label in trainY])\n",
    "    testY_int = np.array([label_to_int[label] for label in testY])\n",
    "\n",
    "    # Compute the mean vectors for each class in the training set\n",
    "    class_means = {}\n",
    "    for label in set(trainY_int):\n",
    "        class_means[label] = np.mean(trainX[trainY_int == label], axis=0)\n",
    "\n",
    "    # Use the class means as the label vectors\n",
    "    label_vectors = np.array(list(class_means.values()))\n",
    "\n",
    "    # Classify the test samples using the k-nearest class mean algorithm\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    knn_clf.fit(label_vectors, list(class_means.keys()))\n",
    "    nn_indices = knn_clf.kneighbors(testX, return_distance=False)\n",
    "\n",
    "    # Compute the predicted labels for each test sample\n",
    "    top_ten_labels_int = np.array([[knn_clf.classes_[i] for i in nn] for nn in nn_indices])\n",
    "\n",
    "    # Convert the label indices to label names and filter out invalid labels\n",
    "    int_to_label = {i: label for label, i in label_to_int.items()}\n",
    "    top_ten_labels = np.vectorize(lambda x: int_to_label.get(x, None))(top_ten_labels_int)\n",
    "    if mode == 'top_1':\n",
    "        top_ten_labels = np.array([labels[labels != None][:1] for labels in top_ten_labels])\n",
    "    if mode == 'top_10':\n",
    "        top_ten_labels = np.array([labels[labels != None][:10] for labels in top_ten_labels])\n",
    "\n",
    "    # Merge testY and top_ten_labels into a DataFrame\n",
    "    df = pd.DataFrame({'testY': testY, 'top_ten_labels': top_ten_labels.tolist()})\n",
    "    lst=[]\n",
    "    for i in range(len(df)):\n",
    "        if df['testY'][i] in df['top_ten_labels'][i]:\n",
    "            score=1\n",
    "        else:\n",
    "            score=0\n",
    "        lst.append(score)\n",
    "    df['score']=lst\n",
    "    avg_df = df.groupby('testY')['score'].mean().reset_index()\n",
    "    avg_df=avg_df.sort_values(by='score',ascending= False)\n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382a5a2",
   "metadata": {},
   "source": [
    "This is for SLPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50599ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_953600/81534717.py:3: DtypeWarning: Columns (2,6,7,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "file_path='total_new.csv'\n",
    "df=pd.read_csv(file_path)\n",
    "df['Metadata_experiment_type'].value_counts()\n",
    "df[\"Metadata_gene\"]=df[\"Metadata_gene\"].fillna('empty')\n",
    "df_fill_empty=df\n",
    "df_negcon=df_fill_empty[df_fill_empty['Metadata_control_type']=='negcon']\n",
    "df_rm_negcon=df_fill_empty[df_fill_empty['Metadata_control_type']!='negcon']\n",
    "df_rm_empty_gene=df_fill_empty[df_fill_empty['Metadata_gene']!='empty']\n",
    "df_rm_orf=df_rm_empty_gene[df_rm_empty_gene[\"Metadata_experiment_type\"]!='ORF']\n",
    "\n",
    "# sampling\n",
    "df_proceed=df_rm_orf[~df_rm_orf['Metadata_pert_type'].isin(['control'])]\n",
    "# Time\n",
    "df_test=df_proceed[df_proceed['Metadata_Plate'].isin(\n",
    "['BR00116996',\n",
    " 'BR00116997',\n",
    " 'BR00116998',\n",
    " 'BR00116999',\n",
    " 'BR00118045',\n",
    " 'BR00118046',\n",
    " 'BR00118047',\n",
    " 'BR00118048'])]\n",
    "df_train=df_proceed[df_proceed['Metadata_Plate'].isin(\n",
    "['BR00116995',\n",
    " 'BR00117010',\n",
    " 'BR00117012',\n",
    " 'BR00117013',\n",
    " 'BR00117024',\n",
    " 'BR00117025',\n",
    " 'BR00117026'])]\n",
    "# Train_test pre-process\n",
    "y_train=df_train['Metadata_gene']\n",
    "trainX=df_train.drop('Metadata_gene', axis = 1)\n",
    "testX=df_test.drop('Metadata_gene', axis = 1)\n",
    "y_test = df_test['Metadata_gene']\n",
    "trainX=trainX.iloc[:,trainX.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\"):]\n",
    "testX=testX.iloc[:,testX.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\"):]\n",
    "trainX=np.array(trainX)\n",
    "testX=np.array(testX)\n",
    "trainY=np.array(y_train)\n",
    "testY=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91f27821",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=300\n",
    "sigma=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51d3eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code from: github.com/tanyapole/reproduce-OSLPP/blob/main/OSLPP.py\n",
    "import scipy \n",
    "\n",
    "def get_l2_norm(features:np.ndarray): return np.sqrt(np.square(features).sum(axis=1)).reshape((-1,1))\n",
    "\n",
    "def get_l2_normalized(features:np.ndarray): return features / get_l2_norm(features)\n",
    "\n",
    "def get_PCA(features, dim):\n",
    "    result = PCA(n_components=dim).fit_transform(features)\n",
    "    assert len(features) == len(result)\n",
    "    return result\n",
    "\n",
    "def get_W(labels,):\n",
    "    W = (labels.reshape(-1,1) == labels).astype(np.int32)\n",
    "    negative_one_idxs = np.where(labels == -1)[0]\n",
    "    W[:,negative_one_idxs] = 0\n",
    "    W[negative_one_idxs,:] = 0\n",
    "    return W\n",
    "\n",
    "def get_D(W): return np.eye(len(W), dtype=np.int32) * W.sum(axis=1)\n",
    "\n",
    "def fix_numerical_assymetry(M): return (M + M.transpose()) * 0.5\n",
    "\n",
    "def get_projection_matrix(features, labels, proj_dim):\n",
    "    N, d = features.shape\n",
    "    X = features.transpose()\n",
    "    \n",
    "    W = get_W(labels)\n",
    "    D = get_D(W)\n",
    "    L = D - W\n",
    "\n",
    "    A = fix_numerical_assymetry(np.matmul(np.matmul(X, D), X.transpose()))\n",
    "    B = fix_numerical_assymetry(np.matmul(np.matmul(X, L), X.transpose()) + np.eye(d))\n",
    "    assert (A.transpose() == A).all() and (B.transpose() == B).all()\n",
    "\n",
    "    w, v = scipy.linalg.eigh(A, B)\n",
    "    assert w[0] < w[-1]\n",
    "    w, v = w[-proj_dim:], v[:, -proj_dim:]\n",
    "    assert np.abs(np.matmul(A, v) - w * np.matmul(B, v)).max() < 1e-5\n",
    "\n",
    "    w = np.flip(w)\n",
    "    v = np.flip(v, axis=1)\n",
    "\n",
    "    for i in range(v.shape[1]):\n",
    "        if v[0,i] < 0:\n",
    "            v[:,i] *= -1\n",
    "    return v\n",
    "\n",
    "def project_features(P, features):\n",
    "    # P: pca_dim x proj_dim\n",
    "    # features: N x pca_dim\n",
    "    # result: N x proj_dim\n",
    "    return np.matmul(P.transpose(), features.transpose()).transpose()\n",
    "\n",
    "y_train_array = np.array(y_train)\n",
    "P = get_projection_matrix(trainX, y_train_array, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3a45e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data feature  from 904 to 300 dimension\n",
    "transformed_data = np.dot(df_train.iloc[:,15:], P)\n",
    "new_feature=pd.DataFrame(transformed_data)\n",
    "trainX1=df_train.iloc[:,:df_train.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\")]\n",
    "trainX1=trainX1.reset_index()\n",
    "dftrain_trans =pd.concat([trainX1,new_feature],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed7f7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform SEEN test data feature  from 904 to 300 dimension\n",
    "transformed_data = np.dot(testX, P)\n",
    "new_feature=pd.DataFrame(transformed_data)\n",
    "testX1=df_test.iloc[:,:df_test.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\")]\n",
    "testX1=testX1.reset_index()\n",
    "dfnew1 =pd.concat([testX1,new_feature],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba9e253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for training KNCM\n",
    "y_train=dftrain_trans['Metadata_gene']\n",
    "trainX=dftrain_trans.drop('Metadata_gene', axis = 1)\n",
    "trainX=trainX.iloc[:,trainX.columns.get_loc(0):]\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "y_test=dfnew1['Metadata_gene']\n",
    "testX=dfnew1.drop('Metadata_gene', axis = 1)\n",
    "testX=testX.iloc[:,testX.columns.get_loc(0):]\n",
    "trainY=y_train.tolist()\n",
    "testY=y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fb84fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=130\n",
    "KNCM_seen_result= kNCM(trainX, trainY, testX, testY, k,'top_10')\n",
    "KNCM_seen_result['If_seen']='seen'\n",
    "KNCM_seen_result1= kNCM(trainX, trainY, testX, testY, k,'top_1')\n",
    "KNCM_seen_result1['If_seen']='seen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed7e24fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 0.010096153846153847\n",
      "top10 0.09326923076923077\n"
     ]
    }
   ],
   "source": [
    "print('top1',KNCM_seen_result1['score'].mean())\n",
    "print('top10',KNCM_seen_result['score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99bfed",
   "metadata": {},
   "source": [
    "This is for Cellprofiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e5690ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_953600/81534717.py:3: DtypeWarning: Columns (2,6,7,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "file_path='total_new.csv'\n",
    "df=pd.read_csv(file_path)\n",
    "df['Metadata_experiment_type'].value_counts()\n",
    "df[\"Metadata_gene\"]=df[\"Metadata_gene\"].fillna('empty')\n",
    "df_fill_empty=df\n",
    "df_negcon=df_fill_empty[df_fill_empty['Metadata_control_type']=='negcon']\n",
    "df_rm_negcon=df_fill_empty[df_fill_empty['Metadata_control_type']!='negcon']\n",
    "df_rm_empty_gene=df_fill_empty[df_fill_empty['Metadata_gene']!='empty']\n",
    "df_rm_orf=df_rm_empty_gene[df_rm_empty_gene[\"Metadata_experiment_type\"]!='ORF']\n",
    "\n",
    "# sampling\n",
    "df_proceed=df_rm_orf[~df_rm_orf['Metadata_pert_type'].isin(['control'])]\n",
    "# Time\n",
    "df_test=df_proceed[df_proceed['Metadata_Plate'].isin(\n",
    "['BR00116996',\n",
    " 'BR00116997',\n",
    " 'BR00116998',\n",
    " 'BR00116999',\n",
    " 'BR00118045',\n",
    " 'BR00118046',\n",
    " 'BR00118047',\n",
    " 'BR00118048'])]\n",
    "df_train=df_proceed[df_proceed['Metadata_Plate'].isin(\n",
    "['BR00116995',\n",
    " 'BR00117010',\n",
    " 'BR00117012',\n",
    " 'BR00117013',\n",
    " 'BR00117024',\n",
    " 'BR00117025',\n",
    " 'BR00117026'])]\n",
    "# Train_test pre-process\n",
    "y_train=df_train['Metadata_gene']\n",
    "trainX=df_train.drop('Metadata_gene', axis = 1)\n",
    "testX=df_test.drop('Metadata_gene', axis = 1)\n",
    "y_test = df_test['Metadata_gene']\n",
    "trainX=trainX.iloc[:,trainX.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\"):]\n",
    "testX=testX.iloc[:,testX.columns.get_loc(\"Cells_AreaShape_BoundingBoxMaximum_Y\"):]\n",
    "trainX=np.array(trainX)\n",
    "testX=np.array(testX)\n",
    "trainY=np.array(y_train)\n",
    "testY=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfa4f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=130\n",
    "CP_seen_result= kNCM(trainX, trainY, testX, testY, k,'top_10')\n",
    "CP_seen_result['If_seen']='seen'\n",
    "CP_seen_result1= kNCM(trainX, trainY, testX, testY, k,'top_1')\n",
    "CP_seen_result1['If_seen']='seen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "925f08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 0.0125\n",
      "top10 0.1201923076923077\n"
     ]
    }
   ],
   "source": [
    "print('top1',CP_seen_result1['score'].mean())\n",
    "print('top10',CP_seen_result['score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a9b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8814d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436c505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d17bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e917c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fbee70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce791d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_std(inputs):\n",
    "    n = len(inputs)\n",
    "    mean = sum(inputs) / n\n",
    "    deviations = [(x - mean) ** 2 for x in inputs]\n",
    "    variance = sum(deviations) / (n - 1)\n",
    "    std = math.sqrt(variance)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs= [0.1215, 0.1121, 0.1039, 0.1009, 0.0904]\n",
    "sum(inputs)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd420275",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_std(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50b485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28402f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "2/((1/ -0.09290380040157403 )+ (1 / -0.16569525556436412) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "2/((1/-0.05152552481428767)+ (1 / -0.24113417272278811 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "2/((1/-0.06922879067464711  )+ (1 / -0.2062534037197309 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "2/((1/ -0.07101392671211575  )+ (1 / -0.18153638829389238 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009d911",
   "metadata": {},
   "outputs": [],
   "source": [
    " 2/((1/ -0.062486664265203704    )+ (1 / -0.19275838514599655   ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d08fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_std(inputs):\n",
    "    n=len(inputs)\n",
    "    mean = sum(inputs)/n\n",
    "    deviations = [(x-mean)**2 for x in inputs]\n",
    "    variance = sum(deviations)/(n-1)\n",
    "    std = math.sqrt(variance)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ca3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[-0.11905471884218397,-0.08490793166781521,-0.10366313324486955,-0.10209143293745622,-0.09437854739753619]\n",
    "sum(inputs)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_std(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ca7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    " 2/((1/ 0.087  )+ (1 / 0.078 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10042068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
